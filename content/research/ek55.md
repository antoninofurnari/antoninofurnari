---
title: "EPIC-KITCHENS-55 DATASET"
date: 2020-01-03
draft: false
bibtex: ["@article{damen2020epic,
  author = {Dima Damen and Hazel Doughty and Giovanni Maria Farinella and Sanja Fidler and Antonino Furnari and Evangelos Kazakos and Davide Moltisanti and Jonathan Munro
           and Toby Perrett and Will Price and Michael Wray},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)},
  title = {The EPIC-KITCHENS Dataset: Collection, Challenges and Baselines},
  url = {https://epic-kitchens.github.io/},
  pdf = {https://arxiv.org/pdf/2005.00343.pdf},
  year = {2020},
  doi = {10.1109/TPAMI.2020.2991965}
}","@inproceedings{Damen2018EPICKITCHENS,
  year = {2018},
  booktitle= { European Conference on Computer Vision },
  author = { D. Damen and H. Doughty and G. M. Farinella and S. Fidler and A.
Furnari and E. Kazakos and D. Moltisanti and J. Munro
and T. Perrett and W. Price and M. Wray },
  title = { Scaling Egocentric Vision: The EPIC-KITCHENS Dataset },
  url={https://epic-kitchens.github.io/2018},
  pdf={https://arxiv.org/pdf/1804.02748.pdf}
}"]
teaser: "https://www.youtube.com/embed/Dj6Y3H0ubDw"
video_teaser: true
---

We introduced EPIC-KITCHENS-55, a large-scale egocentric video benchmark recorded by 32 participants in their native kitchen environments. Our videos depict nonscripted daily activities. Recording took place in 4 cities (in North America and Europe) by participants belonging to 10 different nationalities, resulting in highly diverse kitchen habits and cooking styles. Our dataset features 55 hours of video consisting of 11.5M frames, which we densely labeled for a total of 39.6K action segments and 454.2K object bounding boxes. We describe our object, action and anticipation challenges, and evaluate several baselines over two test splits, seen and unseen kitchens. This work is a joint collaboration between the University of Catania, the University of Bristol and the University of Toronto. [Web Page](https://epic-kitchens.github.io/)