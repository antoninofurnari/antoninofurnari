---
title: "The MECCANO Dataset"
date: 2021-02-01
draft: false
bibtex: ["@inproceedings{ragusa2021meccano,
pdf = { https://arxiv.org/pdf/2010.05654.pdf },
url = { https://iplab.dmi.unict.it/MECCANO },
primaryclass = { cs.CV },
booktitle={IEEE Winter Conference on Application of Computer Vision (WACV)},
eprint = { 2010.05654 },
year = {2021},
author = {Francesco Ragusa and Antonino Furnari and Salvatore Livatino and Giovanni Maria Farinella},
title = {The MECCANO Dataset: Understanding Human-Object Interactions from Egocentric Videos in an Industrial-like Domain}
}","@article{ragusa2023meccano,
  year = {2023},
  title = {MECCANO: A Multimodal Egocentric Dataset for Humans Behavior Understanding in the Industrial-like Domain},
  journal = {Computer Vision and Image Understanding (CVIU)},
  author = {Francesco Ragusa and Antonino Furnari and Giovanni Maria Farinella},
  url = {https://arxiv.org/abs/2209.08691}
}"]
teaser: "meccano.png"
---


In this work, we introduce MECCANO, the first dataset of egocentric videos to study human-object interactions in industrial-like settings. MECCANO has been acquired by 20 participants who were asked to build a motorbike model, for which they had to interact with tiny objects and tools. The dataset has been explicitly labeled for the task of recognizing human-object interactions from an egocentric perspective. Specifically, each interaction has been labeled both temporally (with action segments) and spatially (with active object bounding boxes). With the proposed dataset, we investigate four different tasks including 1) action recognition, 2) active object detection, 3) active object recognition and 4) egocentric human-object interaction detection, which is a revisited version of the standard human-object interaction detection task. Baseline results show that the MECCANO dataset is a challenging benchmark to study egocentric human-object interactions in industrial-like scenarios.
<a href="https://iplab.dmi.unict.it/MECCANO/" target="_blank">Web Page</a>